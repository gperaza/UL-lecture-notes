{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "**IMPORTANT: DO NOT COPY OR SPLIT CELLS.** If you do, you'll mess the autograder. If need more cells to work or test things out, create a new cell. You may add as many new cells as you need.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and group below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COURSE = \"Unsupervised Learning 2021\"\n",
    "GROUP = \"D8A\"\n",
    "NAME = \"\" # Match your GitHub Classroom ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import print_class_limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Discretization\n",
    "\n",
    "In this assignment, you'll be required to implement different discretization strategies, as reviewed in the lectures. You may check your work against the expected outcome in the lecture notes.\n",
    "\n",
    "- Equal frequency (2 pt)\n",
    "- Clustering using 1D k-means (4 pts)\n",
    "- Kernel density estimation (4 pts)\n",
    "\n",
    "As in the lectures, we begin with the creation of some synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from sklearn docs: https://scikit-learn.org/stable/auto_examples/preprocessing/plot_discretization_strategies.html#sphx-glr-auto-examples-preprocessing-plot-discretization-strategies-py\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "n_samples = 200\n",
    "centers_0 = np.array([[0, 0], [0, 5], [2, 4], [8, 8]])\n",
    "centers_1 = np.array([[0, 0], [3, 1]])\n",
    "\n",
    "random_state = 42\n",
    "X_list = [\n",
    "    np.random.RandomState(random_state).uniform(-3, 3, size=(n_samples, 2)),\n",
    "    make_blobs(n_samples=[n_samples // 10, n_samples * 4 // 10,\n",
    "                          n_samples // 10, n_samples * 4 // 10],\n",
    "               cluster_std=0.5, centers=centers_0,\n",
    "               random_state=random_state)[0],\n",
    "    make_blobs(n_samples=[n_samples // 5, n_samples * 4 // 5],\n",
    "               cluster_std=0.5, centers=centers_1,\n",
    "               random_state=random_state)[0],\n",
    "]\n",
    "\n",
    "figure = plt.figure(figsize=(6.4*3, 4.8))\n",
    "for idx, X in enumerate(X_list):\n",
    "    ax = plt.subplot(1, len(X_list), idx+1)\n",
    "    ax.scatter(X[:, 0], X[:, 1], edgecolors='k')\n",
    "\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_xlim(np.min(X[:,0]), np.max(X[:,0]))\n",
    "    ax.set_ylim(np.min(X[:,1]), np.max(X[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equal frecuency (2 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ffae1ee056477db6e6ff0655167595b5",
     "grade": false,
     "grade_id": "cell-fa0b21ee97e705af",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Implement equal frecuency discretization below\n",
    "\n",
    "def disc_eq_freq(X, k):\n",
    "    # Implement equal frequency discretization with k bins.\n",
    "    # Each feature should be discretized individually (univariate discretization).\n",
    "    # Your code should work with a data matrix X with an arbitrary number of unsorted features.\n",
    "    \n",
    "    m, n = X.shape\n",
    "    \n",
    "    # Find class limits.\n",
    "    # Hint: use -inf and +inf as the first and last limit\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    X_disc = np.zeros(X.shape)\n",
    "    for i in range(n):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    # Return the discretized labels in a matrix the same shape as X.\n",
    "    # Return the limits in a matrix which rows are the interval classes of each feature.\n",
    "    return X_disc, clims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the function employ the following test matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61b6df12a9206736b299c38d3e7bd1ca",
     "grade": true,
     "grade_id": "cell-755a3a7461850f7f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_test = np.array([[-2, 1, -4,   -1],\n",
    "                   [-1, 2, -3, -0.5],\n",
    "                   [ 0, 3, -2,  0.5],\n",
    "                   [ 1, 4, -1,    2]])\n",
    "\n",
    "X_disc, bin_edges = disc_eq_freq(X_test, 4)\n",
    "\n",
    "print(\"The discretized matrix is:\")\n",
    "print(X_disc)\n",
    "print(\"Expected answer:\")\n",
    "print(\"\"\"[[0. 0. 0. 0.]\n",
    " [1. 1. 1. 1.]\n",
    " [2. 2. 2. 2.]\n",
    " [3. 3. 3. 3.]]\"\"\")\n",
    "print()\n",
    "\n",
    "print(\"The bin edges are:\")\n",
    "print(bin_edges)\n",
    "print(\"Expected edges:\")\n",
    "print(\"\"\"[[  -inf -1.25  -0.5    0.25     inf]\n",
    " [  -inf  1.75   2.5    3.25     inf]\n",
    " [  -inf -3.25  -2.5   -1.75     inf]\n",
    " [  -inf -0.625  0.     0.875    inf]]\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code plots the sample data sets and the equal frequency partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c37431a014efb220ef16166abbfad1c",
     "grade": false,
     "grade_id": "cell-c352e9d6c47aee09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "bin_edges = [disc_eq_freq(X, 4)[1][:,1:-1] for X in X_list]\n",
    "\n",
    "figure = plt.figure(figsize=(6.4*3, 4.8))\n",
    "for idx, X in enumerate(X_list):\n",
    "    ax = plt.subplot(1, len(X_list), idx+1)\n",
    "    ax.scatter(X[:, 0], X[:, 1], edgecolors='k')\n",
    "    \n",
    "    ax.set_xlim(np.min(X[:,0]), np.max(X[:,0]))\n",
    "    ax.set_ylim(np.min(X[:,1]), np.max(X[:,1]))\n",
    "    \n",
    "    for x in bin_edges[idx][0]:\n",
    "        ax.axvline(x)\n",
    "    for y in bin_edges[idx][1]:\n",
    "        ax.axhline(y)\n",
    "    \n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization by clustering (4 pts)\n",
    "\n",
    "Remember to follow the paper by Daniela Joita, attatched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fedd7b5e06f61a1a4d637ddaffc7a0af",
     "grade": false,
     "grade_id": "cell-1bc52659604d965c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Implement 1D k-means below\n",
    "\n",
    "def k_means_1D(x, k):\n",
    "    \"\"\" Implmentes K-means discretization.\n",
    "    \n",
    "    INPUT:\n",
    "        x: one dimensional numpy array with the features to discretize\n",
    "        k: number of bins\n",
    "        \n",
    "    OUTPUT:\n",
    "        b: the bin edges\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    x = np.array(x)\n",
    "    \n",
    "    # We need an array for the cluster index of each point\n",
    "    cluster = np.zeros(n, dtype=int)\n",
    "    \n",
    "    # Bin edges\n",
    "    b = np.zeros(k + 1)\n",
    "    \n",
    "    # This variable monitors the reallocation of clusters.\n",
    "    # change = true if at least one value is being moved to a different cluster.\n",
    "    change = False\n",
    "    \n",
    "    # Initialize cluster centers to first unique k elements in x\n",
    "    C = []\n",
    "    for e in x:\n",
    "        if e in C:\n",
    "            continue\n",
    "        C.append(e)\n",
    "        if len(C) == k:\n",
    "            break\n",
    "    C = np.sort(C)\n",
    "    if len(C) < k:\n",
    "        assert \"Error, not enough unique centers.\"\n",
    "        \n",
    "    # initialize bin edges\n",
    "    b[0] = -np.inf\n",
    "    b[-1] = np.inf\n",
    "    b[1:-1] = (C[1:] + C[:-1])/2\n",
    "    \n",
    "    # Assign cluster index in cluster list\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Iteration\n",
    "    change = True\n",
    "    while change:\n",
    "        change = False\n",
    "        # Recompute the centers of the clusters as \n",
    "        # the average of the values in each cluster.\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    # Determination of the cut points\n",
    "    b[0] = x.min()\n",
    "    b[-1] = x.max()\n",
    "    b[1:-1] = (C[1:] + C[:-1])/2\n",
    "    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_k_means(X, k):\n",
    "    \"\"\" Implmentes K-means discretization.\n",
    "    \n",
    "    INPUT:\n",
    "        X: data matrix as a numpy array\n",
    "        k: number of bins\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    X_disc = np.zeros(X.shape)\n",
    "    clims = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        bin_edges = k_means_1D(X[:,i], k)\n",
    "        bin_edges[0] = -np.inf\n",
    "        bin_edges[-1] = np.inf\n",
    "        clims.append(list(bin_edges))\n",
    "        X_disc[:,i] = np.searchsorted(bin_edges, X[:,i], side='right') - 1\n",
    "        \n",
    "    return X_disc, np.array(clims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the function employ the following test matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0529ab957b46a8f6c6377883b5cb4286",
     "grade": true,
     "grade_id": "cell-6df3f09d755f5084",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_test = np.array([[-2, 1, -4,   -1],\n",
    "                   [-1, 2, -3, -0.5],\n",
    "                   [ 0, 3, -2,  0.5],\n",
    "                   [ 1, 4, -1,    2]])\n",
    "\n",
    "X_disc, bin_edges = disc_k_means(X_test, 4)\n",
    "\n",
    "print(\"The discretized matrix is:\")\n",
    "print(X_disc)\n",
    "print(\"Expected answer:\")\n",
    "print(\"\"\"[[0. 0. 0. 0.]\n",
    " [1. 1. 1. 1.]\n",
    " [2. 2. 2. 2.]\n",
    " [3. 3. 3. 3.]]\"\"\")\n",
    "print()\n",
    "\n",
    "print(\"The bin edges are:\")\n",
    "print(bin_edges)\n",
    "print(\"Expected edges:\")\n",
    "print(\"\"\"[[ -inf -1.5  -0.5   0.5    inf]\n",
    " [ -inf  1.5   2.5   3.5    inf]\n",
    " [ -inf -3.5  -2.5  -1.5    inf]\n",
    " [ -inf -0.75  0.    1.25   inf]]\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code plots the sample data sets with the found partitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = [disc_k_means(X, 4)[1][:,1:-1] for X in X_list]\n",
    "\n",
    "figure = plt.figure(figsize=(6.4*3, 4.8))\n",
    "for idx, X in enumerate(X_list):\n",
    "    ax = plt.subplot(1, len(X_list), idx+1)\n",
    "    ax.scatter(X[:, 0], X[:, 1], edgecolors='k')\n",
    "    \n",
    "    ax.set_xlim(np.min(X[:,0]), np.max(X[:,0]))\n",
    "    ax.set_ylim(np.min(X[:,1]), np.max(X[:,1]))\n",
    "    \n",
    "    for x in bin_edges[idx][0]:\n",
    "        ax.axvline(x)\n",
    "    for y in bin_edges[idx][1]:\n",
    "        ax.axhline(y)\n",
    "    \n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel density estimation (4 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f355358fcdaf8bb1673d11daf4ddc5f",
     "grade": false,
     "grade_id": "cell-d05adb7dc9ac0e7e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def disc_kde_1D(x, plot=False):\n",
    "    \"\"\" Implmentes KDE discretization.\n",
    "    \n",
    "    INPUT:\n",
    "        x: one dimensional numpy array with the features to discretize\n",
    "               \n",
    "    OUTPUT:\n",
    "        b: the bin edges\n",
    "    \"\"\"\n",
    "    \n",
    "    n = len(x)\n",
    "    x = np.array(x)\n",
    "    x.sort()\n",
    "    \n",
    "    # Select an appropiate bw candidates\n",
    "    xmin = x[0]\n",
    "    xmax = x[-1]\n",
    "    xrange = xmax - xmin\n",
    "    bw_l = np.linspace(0.01*xrange, xrange, 100)\n",
    "    bw_scores = np.zeros(len(bw_l))\n",
    "    \n",
    "    # Use 10-fold CV. Find the corresponding train and test for each fold.\n",
    "    # Note: Since x is ordered, maybe systematic sampling would give better cv results.\n",
    "    folds = list(KFold(n_splits=10, shuffle=True).split(x))\n",
    "    for i, bw in enumerate(bw_l):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    # It seems the best bw benefits from some smoothing, need to explore this more, systematic sampling may solve this.\n",
    "    best_bw = 1.5*bw_l[np.argmax(bw_scores)]\n",
    "        \n",
    "    \n",
    "    # List to store bin edges\n",
    "    bin_edges = [xmin]\n",
    "    \n",
    "    # Fin local minima using a grid, other option is to use data poitns.\n",
    "    grid_x = np.linspace(xmin, xmax, 100)\n",
    "    kde_full = KernelDensity(bandwidth=best_bw, kernel='gaussian').fit(x.reshape(-1,1)).score_samples(grid_x.reshape(-1,1))\n",
    "    \n",
    "    for i in range(1, len(kde_full) - 1):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    bin_edges.append(xmax)\n",
    "    \n",
    "    return np.array(bin_edges)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_kde(X):\n",
    "    m, n = X.shape\n",
    "    X_disc = np.zeros(X.shape)\n",
    "    clims = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        bin_edges = disc_kde_1D(X[:,i])\n",
    "        bin_edges[0] = -np.inf\n",
    "        bin_edges[-1] = np.inf\n",
    "        clims.append(bin_edges)\n",
    "        X_disc[:,i] = np.searchsorted(bin_edges, X[:,i], side='right') - 1\n",
    "    \n",
    "    # Now clims cannot be an array, since there is no guarante\n",
    "    # that all features will have the same number of bins    \n",
    "    return X_disc, clims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the function employ the following test matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfa2eadbe4803366e6615be192b5de43",
     "grade": true,
     "grade_id": "cell-5dac72f09c0bfc46",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_test = np.array([[-2, 1, -4,   -1],\n",
    "                   [-1, 2, -3, -0.5],\n",
    "                   [ 0, 3, -2,  0.5],\n",
    "                   [ 1, 4, -1,    2],\n",
    "                   [-2.1, 1.1, -4.1,   -1.1],\n",
    "                   [-1.1, 2.1, -3.1, -0.6],\n",
    "                   [ 0.1, 3.1, -2.1,  0.6],\n",
    "                   [ 1.1, 4.1, -1.1,    2.1],\n",
    "                   [-2.2, 1.2, -4.2,   -1.2],\n",
    "                   [-1.2, 2.2, -3.2, -0.7],\n",
    "                   [ 0.2, 3.2, -2.2,  0.7],\n",
    "                   [ 1.2, 4.2, -1.2,    2.2]])\n",
    "\n",
    "X_disc, bin_edges = disc_kde(X_test)\n",
    "\n",
    "print(\"The discretized matrix is:\")\n",
    "print(X_disc)\n",
    "print(\"Expected answer:\")\n",
    "print(\"\"\"[[0. 0. 0. 0.]\n",
    " [1. 1. 1. 1.]\n",
    " [1. 1. 1. 2.]\n",
    " [2. 2. 2. 3.]\n",
    " [0. 0. 0. 0.]\n",
    " [1. 1. 1. 1.]\n",
    " [1. 1. 1. 2.]\n",
    " [2. 2. 2. 3.]\n",
    " [0. 0. 0. 0.]\n",
    " [1. 1. 1. 1.]\n",
    " [1. 1. 1. 2.]\n",
    " [2. 2. 2. 3.]]\"\"\")\n",
    "print()\n",
    "\n",
    "print(\"The bin edges are:\")\n",
    "for b in bin_edges:\n",
    "    print(b)\n",
    "print(\"Expected edges:\")\n",
    "print(\"\"\"[       -inf -1.61616162  0.61616162         inf]\n",
    "[      -inf 1.61414141 3.58585859        inf]\n",
    "[       -inf -3.58585859 -1.61414141         inf]\n",
    "[       -inf -0.85656566  0.0020202   1.34141414         inf]\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code plots the sample data sets with the found partitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = [disc_kde(X)[1] for X in X_list]\n",
    "\n",
    "figure = plt.figure(figsize=(6.4*3, 4.8))\n",
    "for idx, X in enumerate(X_list):\n",
    "    ax = plt.subplot(1, len(X_list), idx+1)\n",
    "    ax.scatter(X[:, 0], X[:, 1], edgecolors='k')\n",
    "    \n",
    "    ax.set_xlim(np.min(X[:,0]), np.max(X[:,0]))\n",
    "    ax.set_ylim(np.min(X[:,1]), np.max(X[:,1]))\n",
    "    \n",
    "    for x in bin_edges[idx][0][1:-1]:\n",
    "        ax.axvline(x)\n",
    "    for y in bin_edges[idx][1][1:-1]:\n",
    "        ax.axhline(y)\n",
    "    \n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
